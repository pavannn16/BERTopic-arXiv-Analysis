{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6429f7e5",
      "metadata": {
        "id": "6429f7e5",
        "outputId": "f0a6c78d-e0e1-4d23-e69c-02d017771ca1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install bertopic sentence-transformers umap-learn hdbscan gensim plotly scikit-learn pyyaml gdown -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a448e13a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a448e13a",
        "outputId": "005f2fa2-aedf-451e-876e-62b4f4942dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/BERTopic-arXiv-Analysis'...\n",
            "remote: Enumerating objects: 241, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 241 (delta 59), reused 67 (delta 38), pack-reused 143 (from 1)\u001b[K\n",
            "Receiving objects: 100% (241/241), 181.40 MiB | 16.60 MiB/s, done.\n",
            "Resolving deltas: 100% (127/127), done.\n",
            "Updating files: 100% (66/66), done.\n",
            "Loaded config from /content/BERTopic-arXiv-Analysis/config.yaml\n",
            "Mode: TRAIN\n",
            "Mounted at /content/drive\n",
            "TRAIN mode: Personal Drive mounted\n",
            "Project path: /content/drive/MyDrive/BERTopic-arXiv-Analysis\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# PROJECT SETUP - Config-based with Train/Infer Modes\n",
        "# ============================================================\n",
        "import os\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# Clone repo if running fresh on Colab\n",
        "if 'google.colab' in str(get_ipython()) and not os.path.exists('/content/BERTopic-arXiv-Analysis'):\n",
        "    !git clone https://github.com/pavannn16/BERTopic-arXiv-Analysis.git /content/BERTopic-arXiv-Analysis\n",
        "\n",
        "# Load configuration\n",
        "def load_config():\n",
        "    config_paths = ['config.yaml', '../config.yaml', '/content/BERTopic-arXiv-Analysis/config.yaml']\n",
        "    for path in config_paths:\n",
        "        if os.path.exists(path):\n",
        "            with open(path, 'r') as f:\n",
        "                return yaml.safe_load(f), path\n",
        "    return None, None\n",
        "\n",
        "config, config_path = load_config()\n",
        "if config:\n",
        "    print(f\"Loaded config from {config_path}\")\n",
        "else:\n",
        "    config = {'mode': 'infer'}\n",
        "\n",
        "MODE = config.get('mode', 'infer')\n",
        "print(f\"Mode: {MODE.upper()}\")\n",
        "\n",
        "# Note: Hyperparameter tuning is a TRAIN-only operation\n",
        "# In INFER mode, we load and display existing results\n",
        "if MODE == 'infer':\n",
        "    print(\"INFER mode: Will load existing hyperparameter tuning results\")\n",
        "\n",
        "# Setup paths\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    if MODE == 'train':\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        PROJECT_PATH = '/content/drive/MyDrive/BERTopic-arXiv-Analysis'\n",
        "        print(\"TRAIN mode: Personal Drive mounted\")\n",
        "    else:\n",
        "        PROJECT_PATH = '/content/BERTopic-arXiv-Analysis'\n",
        "        print(\"INFER mode: Using data from cloned repo\")\n",
        "else:\n",
        "    PROJECT_PATH = str(Path(os.getcwd()).parent) if 'notebooks' in os.getcwd() else os.getcwd()\n",
        "    print(\"Running locally\")\n",
        "\n",
        "for folder in ['data/raw', 'data/processed', 'data/embeddings', 'models', 'results']:\n",
        "    os.makedirs(f'{PROJECT_PATH}/{folder}', exist_ok=True)\n",
        "\n",
        "print(f\"Project path: {PROJECT_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4c5545f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c5545f3",
        "outputId": "0cf10148-232f-41d5-d7ef-2b9e3accb74a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported!\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "# BERTopic components\n",
        "from bertopic import BERTopic\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Evaluation\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora import Dictionary\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "print(\"Libraries imported!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bbdbe62d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbdbe62d",
        "outputId": "34fdaa51-3967-43e6-eb1e-bf4c661d83a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: NVIDIA L4\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = 'mps'\n",
        "    print(\"Apple Silicon GPU available\")\n",
        "else:\n",
        "    device = 'cpu'\n",
        "    print(\"No GPU - using CPU (will be slower)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15a9190e",
      "metadata": {
        "id": "15a9190e"
      },
      "source": [
        "## 1. Load Processed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8b4c6639",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b4c6639",
        "outputId": "0b961c40-80a1-463b-8e1f-20ca9718e6aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 19998 documents\n",
            "Date range: 2025-07-03 to 2025-12-02\n",
            "Dictionary size: 24009\n"
          ]
        }
      ],
      "source": [
        "# Load processed data\n",
        "df = pd.read_csv(f\"{PROJECT_PATH}/data/processed/arxiv_cs_ai_processed.csv\")\n",
        "documents = df['text'].tolist()\n",
        "\n",
        "print(f\"Loaded {len(documents)} documents\")\n",
        "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
        "\n",
        "# Prepare tokenized docs for coherence computation\n",
        "tokenized_docs = [doc.lower().split() for doc in documents]\n",
        "dictionary = Dictionary(tokenized_docs)\n",
        "dictionary.filter_extremes(no_below=5, no_above=0.95)\n",
        "print(f\"Dictionary size: {len(dictionary)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a075f668",
      "metadata": {
        "id": "a075f668"
      },
      "source": [
        "## 2. Embedding Model Comparison\n",
        "\n",
        "We compare two popular Sentence-BERT models:\n",
        "\n",
        "| Model | Parameters | Speed | Quality |\n",
        "|-------|------------|-------|--------|\n",
        "| **all-mpnet-base-v2** | 110M | Slower | Higher |\n",
        "| **all-MiniLM-L6-v2** | 22M | 5x faster | Good |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0da2c7da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0da2c7da",
        "outputId": "c33e4a4f-f2e9-4ec9-c334-a047e1737ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-computed mpnet embeddings...\n",
            "Loading pre-computed minilm embeddings...\n",
            "\n",
            "Embeddings ready:\n",
            "  mpnet: (19998, 768)\n",
            "  minilm: (19998, 384)\n"
          ]
        }
      ],
      "source": [
        "# Define embedding models to compare\n",
        "EMBEDDING_MODELS = {\n",
        "    'mpnet': 'all-mpnet-base-v2',\n",
        "    'minilm': 'all-MiniLM-L6-v2'\n",
        "}\n",
        "\n",
        "embeddings_dict = {}\n",
        "\n",
        "for name, model_name in EMBEDDING_MODELS.items():\n",
        "    embeddings_path = f\"{PROJECT_PATH}/data/embeddings/embeddings_{name}.npy\"\n",
        "\n",
        "    if os.path.exists(embeddings_path):\n",
        "        print(f\"Loading pre-computed {name} embeddings...\")\n",
        "        embeddings_dict[name] = np.load(embeddings_path)\n",
        "    else:\n",
        "        print(f\"\\nComputing embeddings with {model_name}...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        model = SentenceTransformer(model_name)\n",
        "        embeddings = model.encode(\n",
        "            documents,\n",
        "            batch_size=64,\n",
        "            show_progress_bar=True,\n",
        "            convert_to_numpy=True,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"  Time: {elapsed:.1f}s ({len(documents)/elapsed:.1f} docs/sec)\")\n",
        "\n",
        "        # Save embeddings\n",
        "        np.save(embeddings_path, embeddings)\n",
        "        embeddings_dict[name] = embeddings\n",
        "        print(f\"  Saved to {embeddings_path}\")\n",
        "\n",
        "print(f\"\\nEmbeddings ready:\")\n",
        "for name, emb in embeddings_dict.items():\n",
        "    print(f\"  {name}: {emb.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "596d597c",
      "metadata": {
        "id": "596d597c"
      },
      "source": [
        "## 3. Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4660a025",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4660a025",
        "outputId": "1ead2c92-66f0-46c5-8aaa-6123406786c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation functions defined!\n"
          ]
        }
      ],
      "source": [
        "def compute_metrics(topic_model, documents, embeddings, topics, tokenized_docs, dictionary):\n",
        "    \"\"\"\n",
        "    Compute all evaluation metrics for a BERTopic model.\n",
        "\n",
        "    Returns:\n",
        "        dict with coherence, diversity, silhouette, n_topics, outlier_pct\n",
        "    \"\"\"\n",
        "    # Get topic words\n",
        "    topics_dict = topic_model.get_topics()\n",
        "    if -1 in topics_dict:\n",
        "        del topics_dict[-1]\n",
        "\n",
        "    n_topics = len(topics_dict)\n",
        "\n",
        "    # Outlier percentage\n",
        "    n_outliers = sum(1 for t in topics if t == -1)\n",
        "    outlier_pct = 100 * n_outliers / len(topics)\n",
        "\n",
        "    # Topic Diversity\n",
        "    all_words = []\n",
        "    topic_words_list = []\n",
        "    for topic_id in sorted(topics_dict.keys()):\n",
        "        words = [word for word, _ in topics_dict[topic_id][:10]]\n",
        "        topic_words_list.append(words)\n",
        "        all_words.extend(words)\n",
        "\n",
        "    diversity = len(set(all_words)) / len(all_words) if all_words else 0\n",
        "\n",
        "    # Coherence (NPMI)\n",
        "    try:\n",
        "        coherence_model = CoherenceModel(\n",
        "            topics=topic_words_list,\n",
        "            texts=tokenized_docs,\n",
        "            dictionary=dictionary,\n",
        "            coherence='c_npmi'\n",
        "        )\n",
        "        coherence = coherence_model.get_coherence()\n",
        "    except:\n",
        "        coherence = 0.0\n",
        "\n",
        "    # Silhouette Score\n",
        "    try:\n",
        "        mask = np.array(topics) != -1\n",
        "        if mask.sum() > 100 and len(set(np.array(topics)[mask])) > 1:\n",
        "            silhouette = silhouette_score(embeddings[mask], np.array(topics)[mask])\n",
        "        else:\n",
        "            silhouette = 0.0\n",
        "    except:\n",
        "        silhouette = 0.0\n",
        "\n",
        "    return {\n",
        "        'n_topics': n_topics,\n",
        "        'outlier_pct': outlier_pct,\n",
        "        'coherence': coherence,\n",
        "        'diversity': diversity,\n",
        "        'silhouette': silhouette,\n",
        "        'combined_score': coherence * 0.5 + diversity * 0.3 + (1 - outlier_pct/100) * 0.2\n",
        "    }\n",
        "\n",
        "print(\"Evaluation functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f402abd4",
      "metadata": {
        "id": "f402abd4"
      },
      "source": [
        "## 4. Hyperparameter Grid Search\n",
        "\n",
        "We'll search over:\n",
        "- **Embedding model**: MPNet vs MiniLM\n",
        "- **min_cluster_size**: [10, 15, 20, 30, 50]\n",
        "- **n_neighbors**: [10, 15, 25]\n",
        "- **n_components**: [5, 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "aa42b6d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa42b6d1",
        "outputId": "1787ade5-7d54-44c6-9934-07b926125dc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total hyperparameter combinations: 60\n",
            "Estimated time: 30 minutes\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameter grid\n",
        "PARAM_GRID = {\n",
        "    'embedding_model': ['mpnet', 'minilm'],\n",
        "    'min_cluster_size': [10, 15, 20, 30, 50],\n",
        "    'n_neighbors': [10, 15, 25],\n",
        "    'n_components': [5, 10]\n",
        "}\n",
        "\n",
        "# Calculate total combinations\n",
        "n_combinations = 1\n",
        "for values in PARAM_GRID.values():\n",
        "    n_combinations *= len(values)\n",
        "\n",
        "print(f\"Total hyperparameter combinations: {n_combinations}\")\n",
        "\n",
        "if MODE == 'infer':\n",
        "    print(\"INFER mode: Will load existing search results instead of running grid search\")\n",
        "else:\n",
        "    print(f\"Estimated time: {n_combinations * 0.5:.0f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f2a5b712",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2a5b712",
        "outputId": "e4e69130-31f4-45bd-92c3-e729b06bd4eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting hyperparameter search...\n",
            "\n",
            "✓ mpnet, mcs=10, nn=10, nc=5 → Topics: 325, Coh: -0.064, Div: 0.729, Out: 33.1%\n",
            "✓ mpnet, mcs=10, nn=10, nc=10 → Topics: 307, Coh: -0.046, Div: 0.723, Out: 30.9%\n",
            "✓ mpnet, mcs=10, nn=15, nc=5 → Topics: 263, Coh: -0.035, Div: 0.730, Out: 32.4%\n",
            "✓ mpnet, mcs=10, nn=15, nc=10 → Topics: 261, Coh: -0.043, Div: 0.746, Out: 31.1%\n",
            "✓ mpnet, mcs=10, nn=25, nc=5 → Topics: 235, Coh: -0.029, Div: 0.734, Out: 32.9%\n",
            "✓ mpnet, mcs=10, nn=25, nc=10 → Topics: 227, Coh: -0.029, Div: 0.752, Out: 33.1%\n",
            "✓ mpnet, mcs=15, nn=10, nc=5 → Topics: 239, Coh: -0.023, Div: 0.734, Out: 29.3%\n",
            "✓ mpnet, mcs=15, nn=10, nc=10 → Topics: 236, Coh: -0.015, Div: 0.732, Out: 28.4%\n",
            "✓ mpnet, mcs=15, nn=15, nc=5 → Topics: 212, Coh: -0.006, Div: 0.740, Out: 29.2%\n",
            "✓ mpnet, mcs=15, nn=15, nc=10 → Topics: 205, Coh: -0.012, Div: 0.752, Out: 28.9%\n",
            "✓ mpnet, mcs=15, nn=25, nc=5 → Topics: 192, Coh: -0.000, Div: 0.753, Out: 32.9%\n",
            "✓ mpnet, mcs=15, nn=25, nc=10 → Topics: 182, Coh: 0.003, Div: 0.768, Out: 31.2%\n",
            "✓ mpnet, mcs=20, nn=10, nc=5 → Topics: 179, Coh: 0.004, Div: 0.754, Out: 26.7%\n",
            "✓ mpnet, mcs=20, nn=10, nc=10 → Topics: 188, Coh: -0.005, Div: 0.757, Out: 27.1%\n",
            "✓ mpnet, mcs=20, nn=15, nc=5 → Topics: 166, Coh: 0.031, Div: 0.760, Out: 27.8%\n",
            "✓ mpnet, mcs=20, nn=15, nc=10 → Topics: 148, Coh: 0.017, Div: 0.786, Out: 24.8%\n",
            "✓ mpnet, mcs=20, nn=25, nc=5 → Topics: 150, Coh: 0.023, Div: 0.766, Out: 30.6%\n",
            "✓ mpnet, mcs=20, nn=25, nc=10 → Topics: 134, Coh: 0.025, Div: 0.781, Out: 25.7%\n",
            "✓ mpnet, mcs=30, nn=10, nc=5 → Topics: 136, Coh: 0.022, Div: 0.781, Out: 25.3%\n",
            "✓ mpnet, mcs=30, nn=10, nc=10 → Topics: 128, Coh: 0.013, Div: 0.784, Out: 22.3%\n",
            "✓ mpnet, mcs=30, nn=15, nc=5 → Topics: 125, Coh: 0.032, Div: 0.784, Out: 25.0%\n",
            "✓ mpnet, mcs=30, nn=15, nc=10 → Topics: 117, Coh: 0.028, Div: 0.792, Out: 24.6%\n",
            "✓ mpnet, mcs=30, nn=25, nc=5 → Topics: 108, Coh: 0.034, Div: 0.794, Out: 27.7%\n",
            "✓ mpnet, mcs=30, nn=25, nc=10 → Topics: 99, Coh: 0.037, Div: 0.812, Out: 25.9%\n",
            "✓ mpnet, mcs=50, nn=10, nc=5 → Topics: 89, Coh: 0.048, Div: 0.822, Out: 22.8%\n",
            "✓ mpnet, mcs=50, nn=10, nc=10 → Topics: 87, Coh: 0.040, Div: 0.830, Out: 22.5%\n",
            "✓ mpnet, mcs=50, nn=15, nc=5 → Topics: 89, Coh: 0.052, Div: 0.822, Out: 25.0%\n",
            "✓ mpnet, mcs=50, nn=15, nc=10 → Topics: 79, Coh: 0.047, Div: 0.833, Out: 22.5%\n",
            "✓ mpnet, mcs=50, nn=25, nc=5 → Topics: 80, Coh: 0.050, Div: 0.850, Out: 27.4%\n",
            "✓ mpnet, mcs=50, nn=25, nc=10 → Topics: 69, Coh: 0.036, Div: 0.865, Out: 23.7%\n",
            "✓ minilm, mcs=10, nn=10, nc=5 → Topics: 255, Coh: -0.031, Div: 0.735, Out: 34.2%\n",
            "✓ minilm, mcs=10, nn=10, nc=10 → Topics: 245, Coh: -0.033, Div: 0.744, Out: 34.2%\n",
            "✓ minilm, mcs=10, nn=15, nc=5 → Topics: 220, Coh: -0.022, Div: 0.756, Out: 36.8%\n",
            "✓ minilm, mcs=10, nn=15, nc=10 → Topics: 208, Coh: -0.029, Div: 0.746, Out: 36.3%\n",
            "✓ minilm, mcs=10, nn=25, nc=5 → Topics: 197, Coh: -0.021, Div: 0.750, Out: 40.9%\n",
            "✓ minilm, mcs=10, nn=25, nc=10 → Topics: 210, Coh: -0.024, Div: 0.750, Out: 42.9%\n",
            "✓ minilm, mcs=15, nn=10, nc=5 → Topics: 203, Coh: -0.012, Div: 0.745, Out: 33.4%\n",
            "✓ minilm, mcs=15, nn=10, nc=10 → Topics: 201, Coh: -0.009, Div: 0.749, Out: 32.6%\n",
            "✓ minilm, mcs=15, nn=15, nc=5 → Topics: 186, Coh: -0.007, Div: 0.749, Out: 35.3%\n",
            "✓ minilm, mcs=15, nn=15, nc=10 → Topics: 184, Coh: -0.010, Div: 0.757, Out: 35.1%\n",
            "✓ minilm, mcs=15, nn=25, nc=5 → Topics: 168, Coh: 0.004, Div: 0.752, Out: 40.3%\n",
            "✓ minilm, mcs=15, nn=25, nc=10 → Topics: 171, Coh: -0.003, Div: 0.752, Out: 41.7%\n",
            "✓ minilm, mcs=20, nn=10, nc=5 → Topics: 162, Coh: 0.004, Div: 0.751, Out: 32.5%\n",
            "✓ minilm, mcs=20, nn=10, nc=10 → Topics: 155, Coh: 0.018, Div: 0.761, Out: 30.0%\n",
            "✓ minilm, mcs=20, nn=15, nc=5 → Topics: 142, Coh: 0.024, Div: 0.761, Out: 33.3%\n",
            "✓ minilm, mcs=20, nn=15, nc=10 → Topics: 145, Coh: 0.008, Div: 0.759, Out: 34.9%\n",
            "✓ minilm, mcs=20, nn=25, nc=5 → Topics: 130, Coh: 0.031, Div: 0.780, Out: 39.1%\n",
            "✓ minilm, mcs=20, nn=25, nc=10 → Topics: 131, Coh: 0.021, Div: 0.773, Out: 40.7%\n",
            "✓ minilm, mcs=30, nn=10, nc=5 → Topics: 117, Coh: 0.033, Div: 0.788, Out: 31.1%\n",
            "✓ minilm, mcs=30, nn=10, nc=10 → Topics: 117, Coh: 0.046, Div: 0.787, Out: 31.2%\n",
            "✓ minilm, mcs=30, nn=15, nc=5 → Topics: 107, Coh: 0.052, Div: 0.786, Out: 34.2%\n",
            "✓ minilm, mcs=30, nn=15, nc=10 → Topics: 105, Coh: 0.044, Div: 0.795, Out: 36.1%\n",
            "✓ minilm, mcs=30, nn=25, nc=5 → Topics: 99, Coh: 0.049, Div: 0.812, Out: 39.1%\n",
            "✓ minilm, mcs=30, nn=25, nc=10 → Topics: 97, Coh: 0.049, Div: 0.811, Out: 41.0%\n",
            "✓ minilm, mcs=50, nn=10, nc=5 → Topics: 81, Coh: 0.021, Div: 0.852, Out: 25.8%\n",
            "✓ minilm, mcs=50, nn=10, nc=10 → Topics: 84, Coh: 0.040, Div: 0.848, Out: 30.9%\n",
            "✓ minilm, mcs=50, nn=15, nc=5 → Topics: 78, Coh: 0.037, Div: 0.855, Out: 33.8%\n",
            "✓ minilm, mcs=50, nn=15, nc=10 → Topics: 76, Coh: 0.046, Div: 0.858, Out: 37.1%\n",
            "✓ minilm, mcs=50, nn=25, nc=5 → Topics: 71, Coh: 0.042, Div: 0.882, Out: 37.2%\n",
            "✓ minilm, mcs=50, nn=25, nc=10 → Topics: 74, Coh: 0.045, Div: 0.872, Out: 40.0%\n",
            "\n",
            "============================================================\n",
            "GRID SEARCH COMPLETE!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Run grid search (TRAIN mode) or load existing results (INFER mode)\n",
        "# ============================================================\n",
        "if MODE == 'infer':\n",
        "    print(\"INFER mode: Skipping grid search (loading existing results)\")\n",
        "    print(\"   Grid search takes ~30 minutes - results are pre-computed\")\n",
        "else:\n",
        "    # TRAIN MODE - Run full grid search\n",
        "    results = []\n",
        "    best_score = -float('inf')\n",
        "    best_params = None\n",
        "    best_model = None\n",
        "\n",
        "    print(\"Starting hyperparameter search...\\n\")\n",
        "\n",
        "    for emb_name in PARAM_GRID['embedding_model']:\n",
        "        embeddings = embeddings_dict[emb_name]\n",
        "\n",
        "        for min_cluster_size in PARAM_GRID['min_cluster_size']:\n",
        "            for n_neighbors in PARAM_GRID['n_neighbors']:\n",
        "                for n_components in PARAM_GRID['n_components']:\n",
        "\n",
        "                    params = {\n",
        "                        'embedding_model': emb_name,\n",
        "                        'min_cluster_size': min_cluster_size,\n",
        "                        'n_neighbors': n_neighbors,\n",
        "                        'n_components': n_components\n",
        "                    }\n",
        "\n",
        "                    try:\n",
        "                        # Build model\n",
        "                        umap_model = UMAP(\n",
        "                            n_neighbors=n_neighbors,\n",
        "                            n_components=n_components,\n",
        "                            min_dist=0.0,\n",
        "                            metric='cosine',\n",
        "                            random_state=42\n",
        "                        )\n",
        "\n",
        "                        hdbscan_model = HDBSCAN(\n",
        "                            min_cluster_size=min_cluster_size,\n",
        "                            min_samples=10,\n",
        "                            metric='euclidean',\n",
        "                            cluster_selection_method='eom',\n",
        "                            prediction_data=True\n",
        "                        )\n",
        "\n",
        "                        vectorizer_model = CountVectorizer(\n",
        "                            ngram_range=(1, 2),\n",
        "                            stop_words='english',\n",
        "                            min_df=5,\n",
        "                            max_df=0.95\n",
        "                        )\n",
        "\n",
        "                        topic_model = BERTopic(\n",
        "                            umap_model=umap_model,\n",
        "                            hdbscan_model=hdbscan_model,\n",
        "                            vectorizer_model=vectorizer_model,\n",
        "                            top_n_words=10,\n",
        "                            calculate_probabilities=False,\n",
        "                            verbose=False\n",
        "                        )\n",
        "\n",
        "                        # Fit model\n",
        "                        topics, _ = topic_model.fit_transform(documents, embeddings=embeddings)\n",
        "\n",
        "                        # Compute metrics\n",
        "                        metrics = compute_metrics(\n",
        "                            topic_model, documents, embeddings, topics,\n",
        "                            tokenized_docs, dictionary\n",
        "                        )\n",
        "                        metrics.update(params)\n",
        "                        results.append(metrics)\n",
        "\n",
        "                        # Check if best\n",
        "                        if metrics['combined_score'] > best_score:\n",
        "                            best_score = metrics['combined_score']\n",
        "                            best_params = params.copy()\n",
        "                            best_model = topic_model\n",
        "                            best_topics = topics\n",
        "                            best_embeddings = embeddings\n",
        "\n",
        "                        print(f\"✓ {emb_name}, mcs={min_cluster_size}, nn={n_neighbors}, nc={n_components} → \"\n",
        "                              f\"Topics: {metrics['n_topics']}, Coh: {metrics['coherence']:.3f}, \"\n",
        "                              f\"Div: {metrics['diversity']:.3f}, Out: {metrics['outlier_pct']:.1f}%\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"✗ {emb_name}, mcs={min_cluster_size}, nn={n_neighbors}, nc={n_components} → Error: {str(e)[:50]}\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"GRID SEARCH COMPLETE!\")\n",
        "    print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "dc0f22d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc0f22d7",
        "outputId": "949f4ad9-b1e7-4291-f4a1-9394c27e8a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to /content/drive/MyDrive/BERTopic-arXiv-Analysis/results/hyperparameter_search_results.csv\n",
            "\n",
            "Top 10 Configurations:\n",
            "embedding_model  min_cluster_size  n_neighbors  n_components  n_topics  coherence  diversity  outlier_pct  combined_score\n",
            "          mpnet                50           25            10        69   0.036245   0.865217    23.732373        0.430223\n",
            "          mpnet                50           15            10        79   0.046542   0.832911    22.532253        0.428080\n",
            "          mpnet                50           10             5        89   0.048002   0.822472    22.752275        0.425238\n",
            "          mpnet                50           25             5        80   0.050174   0.850000    27.442744        0.425201\n",
            "          mpnet                50           10            10        87   0.039587   0.829885    22.492249        0.423775\n",
            "          mpnet                50           15             5        89   0.052408   0.822472    25.017502        0.422911\n",
            "         minilm                50           10             5        81   0.020936   0.851852    25.822582        0.414379\n",
            "         minilm                50           10            10        84   0.039602   0.847619    30.873087        0.412340\n",
            "         minilm                50           25             5        71   0.042284   0.881690    37.168717        0.411312\n",
            "          mpnet                30           25            10        99   0.037492   0.812121    25.877588        0.410627\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Load or create results DataFrame\n",
        "# ============================================================\n",
        "results_path = f\"{PROJECT_PATH}/results/hyperparameter_search_results.csv\"\n",
        "\n",
        "if MODE == 'infer':\n",
        "    print(\"INFER mode: Loading existing hyperparameter search results...\")\n",
        "    results_df = pd.read_csv(results_path)\n",
        "    print(f\"Loaded {len(results_df)} configurations from previous search\")\n",
        "else:\n",
        "    # TRAIN MODE - Create from grid search results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(results_path, index=False)\n",
        "    print(f\"Results saved to {results_path}\")\n",
        "\n",
        "results_df = results_df.sort_values('combined_score', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Configurations:\")\n",
        "display_cols = ['embedding_model', 'min_cluster_size', 'n_neighbors', 'n_components',\n",
        "                'n_topics', 'coherence', 'diversity', 'outlier_pct', 'combined_score']\n",
        "print(results_df[display_cols].head(10).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d2771013",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "d2771013",
        "outputId": "bf6d6c87-b348-45d6-9dd4-5bc991a7323d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/BERTopic-arXiv-Analysis/results/hyperparameter_analysis.html\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"44f17eb2-7ef2-42fa-a088-040420a89510\" class=\"plotly-graph-div\" style=\"height:700px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"44f17eb2-7ef2-42fa-a088-040420a89510\")) {                    Plotly.newPlot(                        \"44f17eb2-7ef2-42fa-a088-040420a89510\",                        [{\"mode\":\"lines+markers\",\"name\":\"mpnet\",\"x\":[10,15,20,30,50],\"y\":[-0.04100112470489845,-0.008825999255575845,0.015675846524208066,0.027828728376785194,0.045493052353427994],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines+markers\",\"name\":\"minilm\",\"x\":[10,15,20,30,50],\"y\":[-0.02662878232542945,-0.006099303806175385,0.017382247445171528,0.04538403519716185,0.03837750051872104],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"error_y\":{\"array\":[0.028356753469394216,0.03224199304275282],\"type\":\"data\"},\"name\":\"Coherence\",\"showlegend\":false,\"x\":[\"minilm\",\"mpnet\"],\"y\":[0.013683139405889918,0.00783410065878939],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":[0.43022306433777746,0.4280799912416957,0.4252377914434039,0.4252014277673831,0.4237746050076385,0.4229107818046157,0.4143785197535347,0.4123404594329767,0.41131151860947257,0.4106271732557027,0.4074553005168307,0.4060800531119743,0.4036973702076351,0.40250043499966626,0.4010643938050158,0.4001162334700378,0.39703770508275116,0.39671132824875377,0.39513811079806543,0.3945449000435376,0.39449564183177455,0.3933939500667587,0.3906082589879972,0.3896948032213749,0.3882827858274518,0.38782333371556965,0.38600678613585304,0.3798680705558497,0.3773355530145232,0.37500147640644976,0.373597888777386,0.37133706783602727,0.3704137483238351,0.3694893386865554,0.36220888297759307,0.3616657985461448,0.3616351672176266,0.36082815153070336,0.3607997745661575,0.3599840808853927,0.3554475074139628,0.35485628765246047,0.35194885410409027,0.35080252374897647,0.3507800678624691,0.35012161615738024,0.34697244659576565,0.34506527449387225,0.34192576236043193,0.3406363229830319,0.34001153913068977,0.33959050843632255,0.33862832852566815,0.3369421818855134,0.3366220356643985,0.3365503238158315,0.3324973444939754,0.3318111955918331,0.327385037652461,0.3204178275735667],\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"mode\":\"markers\",\"name\":\"Configs\",\"showlegend\":false,\"x\":[69,79,89,80,87,89,81,84,71,99,78,76,74,117,125,108,128,117,134,136,148,107,117,99,105,166,97,150,155,179,142,130,188,182,162,145,205,131,212,192,236,201,184,203,186,239,168,227,220,171,261,235,245,263,255,208,197,307,210,325],\"y\":[0.0362451868422412,0.04654215994164367,0.048001537729482964,0.05017383263247601,0.03958717243220836,0.05240842454251575,0.020936257428861536,0.03960183952944824,0.04228382019865167,0.03749197027378163,0.03692718730767351,0.04593811560383396,0.04457778304385731,0.028186111600415762,0.0318588006113317,0.03433687738111965,0.013168085057991651,0.045867439437340125,0.02452827366700963,0.021930525336070747,0.016534700167361634,0.05209280445572524,0.032748440399005985,0.0485125187339789,0.04371714395499081,0.03123467201473013,0.049365864201930065,0.022608388336421884,0.017708893678779133,0.004259663400159389,0.023548525505623488,0.03098976723521083,-0.005110618440434268,0.003061690069984883,0.003810038515775472,0.007593126693525584,-0.012295163577962679,0.020643133042114663,-0.005502368606628621,-0.00031367891328307196,-0.014795655934065914,-0.009306610195718703,-0.009521285865139778,-0.01185816089185162,-0.006660589573398045,-0.023110818571499662,0.003969574231063821,-0.02882994618071501,-0.022379198351443426,-0.003218750542007982,-0.04292080233357647,-0.029216018575580573,-0.03258353513114721,-0.03473362350298575,-0.030923427774054466,-0.029237124607099246,-0.021076649110326074,-0.046286013337567704,-0.02357275897850628,-0.0640203442989652],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":[0.43022306433777746,0.4280799912416957,0.4252377914434039,0.4252014277673831,0.4237746050076385,0.4229107818046157,0.4143785197535347,0.4123404594329767,0.41131151860947257,0.4106271732557027,0.4074553005168307,0.4060800531119743,0.4036973702076351,0.40250043499966626,0.4010643938050158,0.4001162334700378,0.39703770508275116,0.39671132824875377,0.39513811079806543,0.3945449000435376,0.39449564183177455,0.3933939500667587,0.3906082589879972,0.3896948032213749,0.3882827858274518,0.38782333371556965,0.38600678613585304,0.3798680705558497,0.3773355530145232,0.37500147640644976,0.373597888777386,0.37133706783602727,0.3704137483238351,0.3694893386865554,0.36220888297759307,0.3616657985461448,0.3616351672176266,0.36082815153070336,0.3607997745661575,0.3599840808853927,0.3554475074139628,0.35485628765246047,0.35194885410409027,0.35080252374897647,0.3507800678624691,0.35012161615738024,0.34697244659576565,0.34506527449387225,0.34192576236043193,0.3406363229830319,0.34001153913068977,0.33959050843632255,0.33862832852566815,0.3369421818855134,0.3366220356643985,0.3365503238158315,0.3324973444939754,0.3318111955918331,0.327385037652461,0.3204178275735667],\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"mode\":\"markers\",\"name\":\"Configs\",\"showlegend\":false,\"x\":[23.73237323732373,22.53225322532253,22.752275227522752,27.442744274427444,22.492249224922492,25.01750175017502,25.82258225822582,30.873087308730874,37.16871687168717,25.877587758775878,33.77337733773378,37.12871287128713,40.039003900390036,24.64246424642464,25.032503250325032,27.69276927692769,22.31223122312231,31.18811881188119,25.65256525652565,25.34253425342534,24.75747574757476,34.22342234223422,31.08810881088109,39.0989098909891,36.07360736073608,27.842784278427843,41.03910391039104,30.618061806180616,29.952995299529952,26.692669266926693,33.278327832783276,39.078907890789075,27.052705270527053,31.15811581158116,32.53325332533253,34.858485848584856,28.937893789378936,40.73907390739074,29.16791679167917,32.8982898289829,28.40784078407841,32.63326332633263,35.12351235123512,33.35833583358336,35.28352835283528,29.307930793079308,40.27402740274027,33.12331233123312,36.828682868286826,41.684168416841686,31.103110311031102,32.943294329432945,34.21342134213421,32.408240824082405,34.193419341934195,36.33863386338634,40.94409440944094,30.943094309430943,42.914291429142914,33.078307830783075],\"y\":[0.0362451868422412,0.04654215994164367,0.048001537729482964,0.05017383263247601,0.03958717243220836,0.05240842454251575,0.020936257428861536,0.03960183952944824,0.04228382019865167,0.03749197027378163,0.03692718730767351,0.04593811560383396,0.04457778304385731,0.028186111600415762,0.0318588006113317,0.03433687738111965,0.013168085057991651,0.045867439437340125,0.02452827366700963,0.021930525336070747,0.016534700167361634,0.05209280445572524,0.032748440399005985,0.0485125187339789,0.04371714395499081,0.03123467201473013,0.049365864201930065,0.022608388336421884,0.017708893678779133,0.004259663400159389,0.023548525505623488,0.03098976723521083,-0.005110618440434268,0.003061690069984883,0.003810038515775472,0.007593126693525584,-0.012295163577962679,0.020643133042114663,-0.005502368606628621,-0.00031367891328307196,-0.014795655934065914,-0.009306610195718703,-0.009521285865139778,-0.01185816089185162,-0.006660589573398045,-0.023110818571499662,0.003969574231063821,-0.02882994618071501,-0.022379198351443426,-0.003218750542007982,-0.04292080233357647,-0.029216018575580573,-0.03258353513114721,-0.03473362350298575,-0.030923427774054466,-0.029237124607099246,-0.021076649110326074,-0.046286013337567704,-0.02357275897850628,-0.0640203442989652],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Coherence by min_cluster_size\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Coherence by Embedding Model\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topics vs Coherence\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Outlier % vs Coherence\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Hyperparameter Analysis\"},\"height\":700},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('44f17eb2-7ef2-42fa-a088-040420a89510');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize hyperparameter effects\n",
        "fig = make_subplots(rows=2, cols=2, subplot_titles=[\n",
        "    'Coherence by min_cluster_size',\n",
        "    'Coherence by Embedding Model',\n",
        "    'Topics vs Coherence',\n",
        "    'Outlier % vs Coherence'\n",
        "])\n",
        "\n",
        "# 1. min_cluster_size effect\n",
        "for emb in results_df['embedding_model'].unique():\n",
        "    subset = results_df[results_df['embedding_model'] == emb]\n",
        "    grouped = subset.groupby('min_cluster_size')['coherence'].mean()\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=grouped.index, y=grouped.values, name=emb, mode='lines+markers'),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "# 2. Embedding model comparison\n",
        "emb_comparison = results_df.groupby('embedding_model')['coherence'].agg(['mean', 'std'])\n",
        "fig.add_trace(\n",
        "    go.Bar(x=emb_comparison.index, y=emb_comparison['mean'],\n",
        "           error_y=dict(type='data', array=emb_comparison['std']),\n",
        "           name='Coherence', showlegend=False),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# 3. Topics vs Coherence\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=results_df['n_topics'], y=results_df['coherence'],\n",
        "               mode='markers', name='Configs', showlegend=False,\n",
        "               marker=dict(color=results_df['combined_score'], colorscale='Viridis')),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "# 4. Outlier % vs Coherence\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=results_df['outlier_pct'], y=results_df['coherence'],\n",
        "               mode='markers', name='Configs', showlegend=False,\n",
        "               marker=dict(color=results_df['combined_score'], colorscale='Viridis')),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "fig.update_layout(height=700, title_text=\"Hyperparameter Analysis\")\n",
        "\n",
        "# Save and display\n",
        "fig.write_html(f\"{PROJECT_PATH}/results/hyperparameter_analysis.html\")\n",
        "print(f\"Saved: {PROJECT_PATH}/results/hyperparameter_analysis.html\")\n",
        "\n",
        "try:\n",
        "    fig.show()\n",
        "except Exception as e:\n",
        "    print(f\"Interactive display unavailable. Open the HTML file to view.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa9474fb",
      "metadata": {
        "id": "fa9474fb"
      },
      "source": [
        "## 5. Best Model Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "46ec3d37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46ec3d37",
        "outputId": "82d031a6-6b20-42fd-db74-6c01339b4d9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "BEST MODEL CONFIGURATION\n",
            "============================================================\n",
            "\n",
            "Embedding Model: mpnet\n",
            "min_cluster_size: 50\n",
            "n_neighbors: 25\n",
            "n_components: 10\n",
            "\n",
            "Metrics:\n",
            "  Topics: 69\n",
            "  Coherence (NPMI): 0.0362\n",
            "  Diversity: 0.8652\n",
            "  Outlier %: 23.7%\n",
            "  Silhouette: 0.0331\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Best Model Configuration\n",
        "# ============================================================\n",
        "print(\"=\"*60)\n",
        "print(\"BEST MODEL CONFIGURATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if MODE == 'infer':\n",
        "    # Load best config from saved file\n",
        "    with open(f\"{PROJECT_PATH}/results/best_config.json\", 'r') as f:\n",
        "        best_config = json.load(f)\n",
        "    best_params = best_config['params']\n",
        "    best_score = best_config['metrics'].get('coherence_npmi', 0) * 0.5 + \\\n",
        "                 best_config['metrics'].get('diversity', 0) * 0.3 + \\\n",
        "                 (1 - best_config['metrics'].get('outlier_pct', 0)/100) * 0.2\n",
        "\n",
        "print(f\"\\nEmbedding Model: {best_params['embedding_model']}\")\n",
        "print(f\"min_cluster_size: {best_params['min_cluster_size']}\")\n",
        "print(f\"n_neighbors: {best_params['n_neighbors']}\")\n",
        "print(f\"n_components: {best_params['n_components']}\")\n",
        "\n",
        "# Get best model metrics from results_df\n",
        "best_metrics = results_df.iloc[0]\n",
        "print(f\"\\nMetrics:\")\n",
        "print(f\"  Topics: {int(best_metrics['n_topics'])}\")\n",
        "print(f\"  Coherence (NPMI): {best_metrics['coherence']:.4f}\")\n",
        "print(f\"  Diversity: {best_metrics['diversity']:.4f}\")\n",
        "print(f\"  Outlier %: {best_metrics['outlier_pct']:.1f}%\")\n",
        "print(f\"  Silhouette: {best_metrics['silhouette']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a002f5b",
      "metadata": {
        "id": "6a002f5b"
      },
      "source": [
        "## 6. Outlier Reduction\n",
        "\n",
        "BERTopic can reassign outliers to their nearest topics using various strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6ccadb21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ccadb21",
        "outputId": "09839fc2-b38b-4c8c-e555-756418cf8ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers before reduction: 4746 (23.7%)\n",
            "\n",
            "Reducing outliers using c-TF-IDF similarity...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-12-03 20:58:17,400 - BERTopic - WARNING: Using a custom list of topic assignments may lead to errors if topic reduction techniques are used afterwards. Make sure that manually assigning topics is the last step in the pipeline.Note that topic embeddings will also be created through weightedc-TF-IDF embeddings instead of centroid embeddings.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers after reduction: 2694 (13.5%)\n",
            "Outliers reduced by: 2052 documents\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Outlier Reduction (TRAIN mode) or load results (INFER mode)\n",
        "# ============================================================\n",
        "if MODE == 'infer':\n",
        "    print(\"INFER mode: Loading outlier reduction results from saved config...\")\n",
        "    with open(f\"{PROJECT_PATH}/results/best_config.json\", 'r') as f:\n",
        "        best_config = json.load(f)\n",
        "    n_outliers_before = best_config['outlier_reduction']['before']\n",
        "    n_outliers_after = best_config['outlier_reduction']['after']\n",
        "    print(f\"Outliers before reduction: {n_outliers_before}\")\n",
        "    print(f\"Outliers after reduction: {n_outliers_after}\")\n",
        "    print(f\"Outliers reduced by: {n_outliers_before - n_outliers_after} documents\")\n",
        "else:\n",
        "    # TRAIN MODE - Run outlier reduction\n",
        "    n_outliers_before = sum(1 for t in best_topics if t == -1)\n",
        "    print(f\"Outliers before reduction: {n_outliers_before} ({100*n_outliers_before/len(best_topics):.1f}%)\")\n",
        "\n",
        "    # Reduce outliers using c-TF-IDF strategy\n",
        "    print(\"\\nReducing outliers using c-TF-IDF similarity...\")\n",
        "    new_topics = best_model.reduce_outliers(\n",
        "        documents,\n",
        "        best_topics,\n",
        "        strategy=\"c-tf-idf\",\n",
        "        threshold=0.1\n",
        "    )\n",
        "\n",
        "    # Update model with new topics\n",
        "    best_model.update_topics(documents, topics=new_topics)\n",
        "\n",
        "    # Count outliers after\n",
        "    n_outliers_after = sum(1 for t in new_topics if t == -1)\n",
        "    print(f\"Outliers after reduction: {n_outliers_after} ({100*n_outliers_after/len(new_topics):.1f}%)\")\n",
        "    print(f\"Outliers reduced by: {n_outliers_before - n_outliers_after} documents\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b5c1241d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5c1241d",
        "outputId": "68ef8a44-faf2-4441-d69e-6410ed49d282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metrics After Outlier Reduction:\n",
            "  Topics: 69\n",
            "  Coherence (NPMI): 0.0475\n",
            "  Diversity: 0.3565\n",
            "  Outlier %: 13.5%\n",
            "  Silhouette: 0.0149\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Final Metrics after Outlier Reduction\n",
        "# ============================================================\n",
        "if MODE == 'infer':\n",
        "    print(\"INFER mode: Loading final metrics from saved config...\")\n",
        "    with open(f\"{PROJECT_PATH}/results/best_config.json\", 'r') as f:\n",
        "        best_config = json.load(f)\n",
        "    final_metrics = best_config['metrics']\n",
        "    print(\"\\nMetrics After Outlier Reduction:\")\n",
        "    print(f\"  Topics: {final_metrics['n_topics']}\")\n",
        "    print(f\"  Coherence (NPMI): {final_metrics['coherence_npmi']:.4f}\")\n",
        "    print(f\"  Diversity: {final_metrics['diversity']:.4f}\")\n",
        "    print(f\"  Outlier %: {final_metrics['outlier_pct']:.1f}%\")\n",
        "    print(f\"  Silhouette: {final_metrics['silhouette']:.4f}\")\n",
        "else:\n",
        "    # TRAIN MODE - Recompute metrics\n",
        "    final_metrics = compute_metrics(\n",
        "        best_model, documents, best_embeddings, new_topics,\n",
        "        tokenized_docs, dictionary\n",
        "    )\n",
        "\n",
        "    print(\"\\nMetrics After Outlier Reduction:\")\n",
        "    print(f\"  Topics: {final_metrics['n_topics']}\")\n",
        "    print(f\"  Coherence (NPMI): {final_metrics['coherence']:.4f}\")\n",
        "    print(f\"  Diversity: {final_metrics['diversity']:.4f}\")\n",
        "    print(f\"  Outlier %: {final_metrics['outlier_pct']:.1f}%\")\n",
        "    print(f\"  Silhouette: {final_metrics['silhouette']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aabdc9c5",
      "metadata": {
        "id": "aabdc9c5"
      },
      "source": [
        "## 7. Embedding Model Comparison Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c5333716",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5333716",
        "outputId": "907abdca-f05f-4ccb-e036-ccf9b2673d34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "EMBEDDING MODEL COMPARISON\n",
            "============================================================\n",
            "                coherence                 diversity         n_topics          outlier_pct         \n",
            "                     mean     std     max      mean     max     mean min  max        mean      min\n",
            "embedding_model                                                                                   \n",
            "minilm             0.0137  0.0284  0.0521    0.7839  0.8817    147.3  71  255     35.7249  25.8226\n",
            "mpnet              0.0078  0.0322  0.0524    0.7755  0.8652    168.5  69  325     27.6988  22.3122\n",
            "\n",
            "Best MPNet coherence: 0.0524\n",
            "Best MiniLM coherence: 0.0521\n",
            "\n",
            "MPNet wins by 0.0003!\n"
          ]
        }
      ],
      "source": [
        "# Compare embedding models\n",
        "emb_summary = results_df.groupby('embedding_model').agg({\n",
        "    'coherence': ['mean', 'std', 'max'],\n",
        "    'diversity': ['mean', 'max'],\n",
        "    'n_topics': ['mean', 'min', 'max'],\n",
        "    'outlier_pct': ['mean', 'min']\n",
        "}).round(4)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EMBEDDING MODEL COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "print(emb_summary.to_string())\n",
        "\n",
        "# Winner determination\n",
        "mpnet_best = results_df[results_df['embedding_model'] == 'mpnet']['coherence'].max()\n",
        "minilm_best = results_df[results_df['embedding_model'] == 'minilm']['coherence'].max()\n",
        "\n",
        "print(f\"\\nBest MPNet coherence: {mpnet_best:.4f}\")\n",
        "print(f\"Best MiniLM coherence: {minilm_best:.4f}\")\n",
        "print(f\"\\n{'MPNet' if mpnet_best > minilm_best else 'MiniLM'} wins by {abs(mpnet_best - minilm_best):.4f}!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "beeb8c70",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "beeb8c70",
        "outputId": "a357fb22-cc2c-4e29-ebaa-6749d5b9841a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/BERTopic-arXiv-Analysis/results/embedding_model_comparison.html\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"644bccdc-3664-4408-b377-9105ffd14089\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"644bccdc-3664-4408-b377-9105ffd14089\")) {                    Plotly.newPlot(                        \"644bccdc-3664-4408-b377-9105ffd14089\",                        [{\"boxpoints\":\"all\",\"jitter\":0.3,\"name\":\"MPNET\",\"y\":[0.0362451868422412,0.04654215994164367,0.048001537729482964,0.05017383263247601,0.03958717243220836,0.05240842454251575,0.03749197027378163,0.028186111600415762,0.0318588006113317,0.03433687738111965,0.013168085057991651,0.02452827366700963,0.021930525336070747,0.016534700167361634,0.03123467201473013,0.022608388336421884,0.004259663400159389,-0.005110618440434268,0.003061690069984883,-0.012295163577962679,-0.005502368606628621,-0.00031367891328307196,-0.014795655934065914,-0.023110818571499662,-0.02882994618071501,-0.04292080233357647,-0.029216018575580573,-0.03473362350298575,-0.046286013337567704,-0.0640203442989652],\"type\":\"box\"},{\"boxpoints\":\"all\",\"jitter\":0.3,\"name\":\"MINILM\",\"y\":[0.020936257428861536,0.03960183952944824,0.04228382019865167,0.03692718730767351,0.04593811560383396,0.04457778304385731,0.045867439437340125,0.05209280445572524,0.032748440399005985,0.0485125187339789,0.04371714395499081,0.049365864201930065,0.017708893678779133,0.023548525505623488,0.03098976723521083,0.003810038515775472,0.007593126693525584,0.020643133042114663,-0.009306610195718703,-0.009521285865139778,-0.01185816089185162,-0.006660589573398045,0.003969574231063821,-0.022379198351443426,-0.003218750542007982,-0.03258353513114721,-0.030923427774054466,-0.029237124607099246,-0.021076649110326074,-0.02357275897850628],\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Coherence Score Distribution: MPNet vs MiniLM\"},\"yaxis\":{\"title\":{\"text\":\"Coherence (NPMI)\"}},\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('644bccdc-3664-4408-b377-9105ffd14089');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualization: MPNet vs MiniLM\n",
        "fig = go.Figure()\n",
        "\n",
        "for emb in ['mpnet', 'minilm']:\n",
        "    subset = results_df[results_df['embedding_model'] == emb]\n",
        "    fig.add_trace(go.Box(\n",
        "        y=subset['coherence'],\n",
        "        name=emb.upper(),\n",
        "        boxpoints='all',\n",
        "        jitter=0.3\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Coherence Score Distribution: MPNet vs MiniLM',\n",
        "    yaxis_title='Coherence (NPMI)',\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "fig.write_html(f\"{PROJECT_PATH}/results/embedding_model_comparison.html\")\n",
        "print(f\"Saved: {PROJECT_PATH}/results/embedding_model_comparison.html\")\n",
        "\n",
        "try:\n",
        "    fig.show()\n",
        "except Exception as e:\n",
        "    print(f\"Interactive display unavailable. Open the HTML file to view.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9132795",
      "metadata": {
        "id": "f9132795"
      },
      "source": [
        "## 8. Save Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "77e675fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77e675fc",
        "outputId": "be8eaba2-3603-4066-851a-0d3f95df7d9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-12-03 20:58:35,728 - BERTopic - WARNING: You are saving a BERTopic model without explicitly defining an embedding model.If you are using a sentence-transformers model or a HuggingFace model supportedby sentence-transformers, please save the model by using a pointer towards that model.For example, `save_embedding_model='sentence-transformers/all-mpnet-base-v2'`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved to /content/drive/MyDrive/BERTopic-arXiv-Analysis/models/bertopic_best_model\n",
            "Configuration saved to best_config.json\n"
          ]
        }
      ],
      "source": [
        "# Save best model\n",
        "if MODE == \"infer\":\n",
        "    best_model_path = f\"{PROJECT_PATH}/models/bertopic_best_model\"\n",
        "    print(f\"INFER MODE: Model already exists at {best_model_path}\")\n",
        "    print(f\"Configuration already saved to best_config.json\")\n",
        "else:\n",
        "    best_model_path = f\"{PROJECT_PATH}/models/bertopic_best_model\"\n",
        "    os.makedirs(best_model_path, exist_ok=True)\n",
        "\n",
        "    best_model.save(\n",
        "        best_model_path,\n",
        "        serialization=\"safetensors\",\n",
        "        save_ctfidf=True,\n",
        "        save_embedding_model=False\n",
        "    )\n",
        "\n",
        "    print(f\"Best model saved to {best_model_path}\")\n",
        "\n",
        "    # Save best configuration\n",
        "    best_config = {\n",
        "        'params': best_params,\n",
        "        'metrics': {\n",
        "            'n_topics': int(final_metrics['n_topics']),\n",
        "            'coherence_npmi': float(final_metrics['coherence']),\n",
        "            'diversity': float(final_metrics['diversity']),\n",
        "            'outlier_pct': float(final_metrics['outlier_pct']),\n",
        "            'silhouette': float(final_metrics['silhouette'])\n",
        "        },\n",
        "        'outlier_reduction': {\n",
        "            'before': n_outliers_before,\n",
        "            'after': n_outliers_after,\n",
        "            'strategy': 'c-tf-idf'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(f\"{PROJECT_PATH}/results/best_config.json\", 'w') as f:\n",
        "        json.dump(best_config, f, indent=2)\n",
        "\n",
        "    print(\"Configuration saved to best_config.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5e244442",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e244442",
        "outputId": "ac5a4027-4a00-4236-9aef-abc3c2f95c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic assignments saved!\n"
          ]
        }
      ],
      "source": [
        "# Save topic assignments with best model\n",
        "if MODE == \"infer\":\n",
        "    print(\"INFER MODE: Topic assignments already saved.\")\n",
        "    assignments_path = f\"{PROJECT_PATH}/results/topic_assignments_best.csv\"\n",
        "    if os.path.exists(assignments_path):\n",
        "        results_df_final = pd.read_csv(assignments_path)\n",
        "        print(f\"Loaded existing assignments: {len(results_df_final)} documents\")\n",
        "else:\n",
        "    results_df_final = df.copy()\n",
        "    results_df_final['topic'] = new_topics\n",
        "\n",
        "    # Add topic labels\n",
        "    topic_info = best_model.get_topic_info()\n",
        "    topic_labels = {row['Topic']: row['Name'] for _, row in topic_info.iterrows()}\n",
        "    results_df_final['topic_name'] = results_df_final['topic'].map(topic_labels)\n",
        "\n",
        "    results_df_final.to_csv(f\"{PROJECT_PATH}/results/topic_assignments_best.csv\", index=False)\n",
        "    topic_info.to_csv(f\"{PROJECT_PATH}/results/topic_info_best.csv\", index=False)\n",
        "\n",
        "    print(\"Topic assignments saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6e3ef915",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e3ef915",
        "outputId": "f58d6bae-d847-49d4-973c-14aa07fa6cb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing 2D UMAP projection...\n",
            "2D embeddings saved!\n"
          ]
        }
      ],
      "source": [
        "# Compute and save 2D embeddings for best model\n",
        "if MODE == \"infer\":\n",
        "    embeddings_2d_path = f\"{PROJECT_PATH}/data/embeddings/embeddings_2d_best.npy\"\n",
        "    print(\"INFER MODE: 2D embeddings already computed.\")\n",
        "    if os.path.exists(embeddings_2d_path):\n",
        "        embeddings_2d = np.load(embeddings_2d_path)\n",
        "        print(f\"Loaded 2D embeddings: shape {embeddings_2d.shape}\")\n",
        "else:\n",
        "    print(\"Computing 2D UMAP projection...\")\n",
        "    umap_2d = UMAP(n_components=2, min_dist=0.1, metric='cosine', random_state=42)\n",
        "    embeddings_2d = umap_2d.fit_transform(best_embeddings)\n",
        "\n",
        "    np.save(f\"{PROJECT_PATH}/data/embeddings/embeddings_2d_best.npy\", embeddings_2d)\n",
        "    print(\"2D embeddings saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "689eb91a",
      "metadata": {
        "id": "689eb91a"
      },
      "source": [
        "## 9. Summary Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9f93c44b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f93c44b",
        "outputId": "665467f2-0415-41da-bc1b-7db8eb2aa49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "HYPERPARAMETER TUNING & MODEL COMPARISON REPORT\n",
            "Project: Topic Modeling arXiv cs.AI with BERTopic\n",
            "Team: Pavan Chauhan, Vedanta Nayak\n",
            "======================================================================\n",
            "\n",
            "HYPERPARAMETER SEARCH\n",
            "--------------------------------------------------\n",
            "Total configurations tested: 60\n",
            "Embedding models: MPNet, MiniLM\n",
            "min_cluster_size: [10, 15, 20, 30, 50]\n",
            "n_neighbors: [10, 15, 25]\n",
            "n_components: [5, 10]\n",
            "\n",
            "EMBEDDING MODEL COMPARISON\n",
            "--------------------------------------------------\n",
            "MPNet (all-mpnet-base-v2):\n",
            "  - Best coherence: 0.0524\n",
            "  - Mean coherence: 0.0078\n",
            "  - Parameters: 110M\n",
            "\n",
            "MiniLM (all-MiniLM-L6-v2):\n",
            "  - Best coherence: 0.0521\n",
            "  - Mean coherence: 0.0137\n",
            "  - Parameters: 22M (5x smaller)\n",
            "\n",
            "BEST MODEL\n",
            "--------------------------------------------------\n",
            "Embedding: MPNET\n",
            "min_cluster_size: 50\n",
            "n_neighbors: 25\n",
            "n_components: 10\n",
            "\n",
            "OUTLIER REDUCTION\n",
            "--------------------------------------------------\n",
            "Strategy: c-TF-IDF similarity\n",
            "Before: 4746 outliers (23.7%)\n",
            "After: 2694 outliers (13.5%)\n",
            "Improvement: 2052 documents reassigned\n",
            "\n",
            "FINAL METRICS\n",
            "--------------------------------------------------\n",
            "Topics: 69\n",
            "Coherence (NPMI): 0.0475\n",
            "Topic Diversity: 0.3565 (35.7%)\n",
            "Silhouette Score: 0.0149\n",
            "Outlier %: 13.5%\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Report saved!\n"
          ]
        }
      ],
      "source": [
        "# Generate comprehensive report\n",
        "# In INFER mode, load from config if needed\n",
        "if MODE == \"infer\":\n",
        "    config_path = f\"{PROJECT_PATH}/results/best_config.json\"\n",
        "    if os.path.exists(config_path):\n",
        "        with open(config_path, 'r') as f:\n",
        "            best_config = json.load(f)\n",
        "        best_params = best_config.get('params', {})\n",
        "        final_metrics = best_config.get('metrics', {})\n",
        "        outlier_info = best_config.get('outlier_reduction', {})\n",
        "        n_outliers_before = outlier_info.get('before', 0)\n",
        "        n_outliers_after = outlier_info.get('after', 0)\n",
        "\n",
        "report = f\"\"\"\n",
        "{'='*70}\n",
        "HYPERPARAMETER TUNING & MODEL COMPARISON REPORT\n",
        "Project: Topic Modeling arXiv cs.AI with BERTopic\n",
        "Team: Pavan Chauhan, Vedanta Nayak\n",
        "{'='*70}\n",
        "\n",
        "HYPERPARAMETER SEARCH\n",
        "{'-'*50}\n",
        "Total configurations tested: {len(results_df)}\n",
        "Embedding models: MPNet, MiniLM\n",
        "min_cluster_size: [10, 15, 20, 30, 50]\n",
        "n_neighbors: [10, 15, 25]\n",
        "n_components: [5, 10]\n",
        "\n",
        "EMBEDDING MODEL COMPARISON\n",
        "{'-'*50}\n",
        "MPNet (all-mpnet-base-v2):\n",
        "  - Best coherence: {results_df[results_df['embedding_model']=='mpnet']['coherence'].max():.4f}\n",
        "  - Mean coherence: {results_df[results_df['embedding_model']=='mpnet']['coherence'].mean():.4f}\n",
        "  - Parameters: 110M\n",
        "\n",
        "MiniLM (all-MiniLM-L6-v2):\n",
        "  - Best coherence: {results_df[results_df['embedding_model']=='minilm']['coherence'].max():.4f}\n",
        "  - Mean coherence: {results_df[results_df['embedding_model']=='minilm']['coherence'].mean():.4f}\n",
        "  - Parameters: 22M (5x smaller)\n",
        "\n",
        "BEST MODEL\n",
        "{'-'*50}\n",
        "Embedding: {best_params.get('embedding_model', 'mpnet').upper()}\n",
        "min_cluster_size: {best_params.get('min_cluster_size', 'N/A')}\n",
        "n_neighbors: {best_params.get('n_neighbors', 'N/A')}\n",
        "n_components: {best_params.get('n_components', 'N/A')}\n",
        "\n",
        "OUTLIER REDUCTION\n",
        "{'-'*50}\n",
        "Strategy: c-TF-IDF similarity\n",
        "Before: {n_outliers_before} outliers ({100*n_outliers_before/len(documents):.1f}%)\n",
        "After: {n_outliers_after} outliers ({100*n_outliers_after/len(documents):.1f}%)\n",
        "Improvement: {n_outliers_before - n_outliers_after} documents reassigned\n",
        "\n",
        "FINAL METRICS\n",
        "{'-'*50}\n",
        "Topics: {final_metrics.get('n_topics', 'N/A')}\n",
        "Coherence (NPMI): {final_metrics.get('coherence_npmi', final_metrics.get('coherence', 0)):.4f}\n",
        "Topic Diversity: {final_metrics.get('diversity', 0):.4f} ({final_metrics.get('diversity', 0)*100:.1f}%)\n",
        "Silhouette Score: {final_metrics.get('silhouette', 0):.4f}\n",
        "Outlier %: {final_metrics.get('outlier_pct', 0):.1f}%\n",
        "\n",
        "{'='*70}\n",
        "\"\"\"\n",
        "\n",
        "print(report)\n",
        "\n",
        "with open(f\"{PROJECT_PATH}/results/hyperparameter_tuning_report.txt\", 'w') as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(f\"Report saved!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}