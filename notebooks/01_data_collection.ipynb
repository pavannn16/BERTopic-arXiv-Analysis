{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8f4a9b22",
      "metadata": {
        "id": "8f4a9b22"
      },
      "source": [
        "# Notebook 1: Data Collection\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pavannn16/BERTopic-arXiv-Analysis/blob/main/notebooks/01_data_collection.ipynb)\n",
        "\n",
        "**Purpose:** Fetch 20,000 arXiv cs.AI paper abstracts using the arXiv API.\n",
        "\n",
        "**Time:** ~15 minutes (API rate limited)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ce2bcb4e",
      "metadata": {
        "id": "ce2bcb4e",
        "outputId": "5bb7e3c5-d9cd-4bda-8704-4ec0b2d7cbf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/81.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (run once in Colab)\n",
        "!pip install arxiv pandas tqdm pyyaml -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "52195bee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52195bee",
        "outputId": "f0e81ae4-1a4f-4f07-f8bd-ab4c968b84b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/BERTopic-arXiv-Analysis'...\n",
            "remote: Enumerating objects: 229, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 229 (delta 50), reused 70 (delta 38), pack-reused 143 (from 1)\u001b[K\n",
            "Receiving objects: 100% (229/229), 181.22 MiB | 38.30 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n",
            "Updating files: 100% (66/66), done.\n",
            "Loaded config from /content/BERTopic-arXiv-Analysis/config.yaml\n",
            "Mode: TRAIN\n",
            "Mounted at /content/drive\n",
            "TRAIN mode: Personal Drive mounted - will fetch fresh data\n",
            "Project path: /content/drive/MyDrive/BERTopic-arXiv-Analysis\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# PROJECT SETUP - Config-based with Train/Infer Modes\n",
        "# ============================================================\n",
        "import os\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# Clone repo if running on Colab\n",
        "if 'google.colab' in str(get_ipython()) and not os.path.exists('/content/BERTopic-arXiv-Analysis'):\n",
        "    !git clone https://github.com/pavannn16/BERTopic-arXiv-Analysis.git /content/BERTopic-arXiv-Analysis\n",
        "\n",
        "# Load configuration\n",
        "def load_config():\n",
        "    config_paths = ['config.yaml', '../config.yaml', '/content/BERTopic-arXiv-Analysis/config.yaml']\n",
        "    for path in config_paths:\n",
        "        if os.path.exists(path):\n",
        "            with open(path, 'r') as f:\n",
        "                return yaml.safe_load(f), path\n",
        "    return None, None\n",
        "\n",
        "config, config_path = load_config()\n",
        "if config:\n",
        "    print(f\"Loaded config from {config_path}\")\n",
        "else:\n",
        "    print(\"Config not found, using defaults\")\n",
        "    config = {'mode': 'infer', 'data': {'arxiv': {'category': 'cs.AI', 'max_results': 20000}}}\n",
        "\n",
        "MODE = config.get('mode', 'infer')\n",
        "print(f\"Mode: {MODE.upper()}\")\n",
        "\n",
        "# Setup paths\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    if MODE == 'train':\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        PROJECT_PATH = '/content/drive/MyDrive/BERTopic-arXiv-Analysis'\n",
        "        print(\"TRAIN mode: Personal Drive mounted - will fetch fresh data\")\n",
        "    else:\n",
        "        PROJECT_PATH = '/content/BERTopic-arXiv-Analysis'\n",
        "        print(\"INFER mode: Using data from cloned repo\")\n",
        "        print(\"Data fetching skipped in INFER mode. Change mode='train' in config.yaml to fetch new data.\")\n",
        "else:\n",
        "    # Running locally\n",
        "    PROJECT_PATH = str(Path(os.getcwd()).parent) if 'notebooks' in os.getcwd() else os.getcwd()\n",
        "    print(\"Running locally\")\n",
        "\n",
        "# Create directories\n",
        "for folder in ['data/raw', 'data/processed', 'data/embeddings', 'models', 'results/visualizations']:\n",
        "    os.makedirs(f'{PROJECT_PATH}/{folder}', exist_ok=True)\n",
        "\n",
        "print(f\"Project path: {PROJECT_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6990ece7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6990ece7",
        "outputId": "23bfdeca-00c7-49fc-814b-a10afc3a0e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import arxiv\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import time\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02ae4f90",
      "metadata": {
        "id": "02ae4f90"
      },
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "17637893",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17637893",
        "outputId": "50a7490b-ba2d-46f7-cd25-94b1f221a8f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category: cs.AI\n",
            "Date range: 2023-12-14 to 2025-12-03\n",
            "Max results: 20000\n"
          ]
        }
      ],
      "source": [
        "# Configuration - loaded from config.yaml or defaults\n",
        "ARXIV_CONFIG = config.get('data', {}).get('arxiv', {})\n",
        "\n",
        "CONFIG = {\n",
        "    'category': ARXIV_CONFIG.get('category', 'cs.AI'),\n",
        "    'max_results': ARXIV_CONFIG.get('max_results', 20000),\n",
        "    'months_back': ARXIV_CONFIG.get('months_back', 24),\n",
        "    'batch_size': ARXIV_CONFIG.get('batch_size', 100),\n",
        "    'delay_seconds': ARXIV_CONFIG.get('delay_seconds', 3.0),\n",
        "}\n",
        "\n",
        "# Calculate date range\n",
        "from datetime import datetime, timedelta\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(days=CONFIG['months_back'] * 30)\n",
        "\n",
        "print(f\"Category: {CONFIG['category']}\")\n",
        "print(f\"Date range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
        "print(f\"Max results: {CONFIG['max_results']}\")\n",
        "\n",
        "# Check mode - skip fetching in INFER mode\n",
        "if MODE == 'infer':\n",
        "    print(\"\\nINFER mode: Skipping data fetch. Data should already exist.\")\n",
        "    print(\"   To fetch fresh data, set mode='train' in config.yaml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32efeca5",
      "metadata": {
        "id": "32efeca5"
      },
      "source": [
        "## 3. Fetch Papers from arXiv API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "025d168b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "025d168b",
        "outputId": "4137520e-11ff-46ef-9cd7-145e1fdc3208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching up to 20000 papers from arXiv category: cs.AI\n",
            "This may take 10.0 minutes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 10000/20000 [06:07<06:07, 27.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Error during fetch: Page request resulted in HTTP 500 (https://export.arxiv.org/api/query?search_query=cat%3Acs.AI&id_list=&sortBy=submittedDate&sortOrder=descending&start=10000&max_results=100)\n",
            "Successfully fetched 10000 papers before error\n",
            "\n",
            "Total papers fetched: 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# TRAIN MODE ONLY - Skip in INFER mode\n",
        "# ============================================================\n",
        "if MODE == 'infer':\n",
        "    print(\"INFER mode: Skipping data fetch (data already exists in repo)\")\n",
        "    print(\"   Loading existing data instead...\")\n",
        "\n",
        "    # Load existing data\n",
        "    df = pd.read_csv(f\"{PROJECT_PATH}/data/raw/arxiv_cs_ai_raw.csv\")\n",
        "    papers = df.to_dict('records')\n",
        "    print(f\"Loaded {len(papers)} papers from existing data\")\n",
        "else:\n",
        "    # TRAIN MODE - Fetch fresh data from arXiv\n",
        "    def fetch_arxiv_papers(category, max_results, batch_size=100, delay=3.0):\n",
        "        \"\"\"\n",
        "        Fetch papers from arXiv API.\n",
        "\n",
        "        Args:\n",
        "            category: arXiv category (e.g., 'cs.AI')\n",
        "            max_results: Maximum number of papers\n",
        "            batch_size: Papers per API request\n",
        "            delay: Delay between requests in seconds\n",
        "\n",
        "        Returns:\n",
        "            List of paper dictionaries\n",
        "        \"\"\"\n",
        "        query = f\"cat:{category}\"\n",
        "\n",
        "        print(f\"Fetching up to {max_results} papers from arXiv category: {category}\")\n",
        "        print(f\"This may take {max_results * delay / 60 / batch_size:.1f} minutes...\")\n",
        "\n",
        "        # Configure search\n",
        "        search = arxiv.Search(\n",
        "            query=query,\n",
        "            max_results=max_results,\n",
        "            sort_by=arxiv.SortCriterion.SubmittedDate,\n",
        "            sort_order=arxiv.SortOrder.Descending\n",
        "        )\n",
        "\n",
        "        # Configure client\n",
        "        client = arxiv.Client(\n",
        "            page_size=batch_size,\n",
        "            delay_seconds=delay,\n",
        "            num_retries=5\n",
        "        )\n",
        "\n",
        "        papers = []\n",
        "\n",
        "        try:\n",
        "            for result in tqdm(client.results(search), total=max_results, desc=\"Fetching\"):\n",
        "                paper = {\n",
        "                    \"arxiv_id\": result.entry_id.split(\"/\")[-1],\n",
        "                    \"title\": result.title.replace(\"\\n\", \" \").strip(),\n",
        "                    \"abstract\": result.summary.replace(\"\\n\", \" \").strip(),\n",
        "                    \"authors\": \", \".join([author.name for author in result.authors[:5]]),\n",
        "                    \"date\": result.published.strftime(\"%Y-%m-%d\"),\n",
        "                    \"year_month\": result.published.strftime(\"%Y-%m\"),\n",
        "                    \"url\": result.entry_id,\n",
        "                    \"categories\": \", \".join(result.categories),\n",
        "                    \"primary_category\": result.primary_category\n",
        "                }\n",
        "                papers.append(paper)\n",
        "\n",
        "                if len(papers) >= max_results:\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError during fetch: {e}\")\n",
        "            print(f\"Successfully fetched {len(papers)} papers before error\")\n",
        "\n",
        "        return papers\n",
        "\n",
        "    # Fetch papers\n",
        "    papers = fetch_arxiv_papers(\n",
        "        category=CONFIG['category'],\n",
        "        max_results=CONFIG['max_results'],\n",
        "        batch_size=CONFIG['batch_size'],\n",
        "        delay=CONFIG['delay_seconds']\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTotal papers fetched: {len(papers)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3a3ea92a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a3ea92a",
        "outputId": "750e41c2-c568-4e05-e1f5-87a3cee8bad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Earliest paper in current batch: 2025-09-26\n",
            "\n",
            "Fetching additional papers from 2025-03-30 to 2025-09-25\n",
            "Fetching papers from 2025-03-30 to 2025-09-25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 9999/10000 [05:43<00:00, 29.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Additional papers fetched: 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# TRAIN MODE ONLY - Fetch additional papers\n",
        "# ============================================================\n",
        "if MODE == 'infer':\n",
        "    print(\"INFER mode: Skipping additional fetch (using existing data)\")\n",
        "else:\n",
        "    # arXiv API has a 10,000 result limit per query\n",
        "    # Let's fetch additional papers by querying different date ranges\n",
        "\n",
        "    def fetch_arxiv_by_date_range(category, start_date, end_date, max_results=10000, batch_size=100, delay=3.0):\n",
        "        \"\"\"Fetch papers within a specific date range.\"\"\"\n",
        "        start_str = start_date.strftime(\"%Y%m%d\")\n",
        "        end_str = end_date.strftime(\"%Y%m%d\")\n",
        "\n",
        "        query = f\"cat:{category} AND submittedDate:[{start_str}0000 TO {end_str}2359]\"\n",
        "\n",
        "        print(f\"Fetching papers from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "        search = arxiv.Search(\n",
        "            query=query,\n",
        "            max_results=max_results,\n",
        "            sort_by=arxiv.SortCriterion.SubmittedDate,\n",
        "            sort_order=arxiv.SortOrder.Descending\n",
        "        )\n",
        "\n",
        "        client = arxiv.Client(\n",
        "            page_size=batch_size,\n",
        "            delay_seconds=delay,\n",
        "            num_retries=5\n",
        "        )\n",
        "\n",
        "        papers = []\n",
        "\n",
        "        try:\n",
        "            for result in tqdm(client.results(search), total=max_results, desc=\"Fetching\"):\n",
        "                paper = {\n",
        "                    \"arxiv_id\": result.entry_id.split(\"/\")[-1],\n",
        "                    \"title\": result.title.replace(\"\\n\", \" \").strip(),\n",
        "                    \"abstract\": result.summary.replace(\"\\n\", \" \").strip(),\n",
        "                    \"authors\": \", \".join([author.name for author in result.authors[:5]]),\n",
        "                    \"date\": result.published.strftime(\"%Y-%m-%d\"),\n",
        "                    \"year_month\": result.published.strftime(\"%Y-%m\"),\n",
        "                    \"url\": result.entry_id,\n",
        "                    \"categories\": \", \".join(result.categories),\n",
        "                    \"primary_category\": result.primary_category\n",
        "                }\n",
        "                papers.append(paper)\n",
        "\n",
        "                if len(papers) >= max_results:\n",
        "                    break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError: {e}\")\n",
        "            print(f\"Fetched {len(papers)} papers before error\")\n",
        "\n",
        "        return papers\n",
        "\n",
        "    # Find the earliest date we have\n",
        "    earliest_date = pd.to_datetime(min([p['date'] for p in papers]))\n",
        "    print(f\"Earliest paper in current batch: {earliest_date.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "    # Fetch earlier papers\n",
        "    end_date_batch2 = earliest_date - timedelta(days=1)\n",
        "    start_date_batch2 = earliest_date - timedelta(days=180)\n",
        "\n",
        "    print(f\"\\nFetching additional papers from {start_date_batch2.strftime('%Y-%m-%d')} to {end_date_batch2.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "    papers_batch2 = fetch_arxiv_by_date_range(\n",
        "        category=CONFIG['category'],\n",
        "        start_date=start_date_batch2,\n",
        "        end_date=end_date_batch2,\n",
        "        max_results=10000,\n",
        "        batch_size=CONFIG['batch_size'],\n",
        "        delay=CONFIG['delay_seconds']\n",
        "    )\n",
        "\n",
        "    print(f\"\\nAdditional papers fetched: {len(papers_batch2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "97f5a0f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97f5a0f5",
        "outputId": "70c286bb-50d7-41f1-ff6e-982d8aedb681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1 (recent): 10000 papers\n",
            "Batch 2 (earlier): 10000 papers\n",
            "Total unique papers: 20000\n",
            "Date range: 2025-07-03 to 2025-12-02\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# TRAIN MODE ONLY - Combine batches and deduplicate\n",
        "# ============================================================\n",
        "if MODE == 'infer':\n",
        "    print(\"INFER mode: Using existing data (already loaded)\")\n",
        "else:\n",
        "    # Check what we have so far\n",
        "    print(f\"Batch 1 (recent): {len(papers)} papers\")\n",
        "    print(f\"Batch 2 (earlier): {len(papers_batch2)} papers\")\n",
        "\n",
        "    # Combine and deduplicate\n",
        "    all_papers = papers + papers_batch2\n",
        "    seen_ids = set()\n",
        "    unique_papers = []\n",
        "    for p in all_papers:\n",
        "        if p['arxiv_id'] not in seen_ids:\n",
        "            seen_ids.add(p['arxiv_id'])\n",
        "            unique_papers.append(p)\n",
        "\n",
        "    print(f\"Total unique papers: {len(unique_papers)}\")\n",
        "\n",
        "    # Check date range\n",
        "    dates = [p['date'] for p in unique_papers]\n",
        "    print(f\"Date range: {min(dates)} to {max(dates)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3ad8d877",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ad8d877",
        "outputId": "04ee2b51-f02c-45e6-d167-3b747a02f9ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final dataset: 20000 papers\n",
            "üìÖ Date range: 2025-07-03 to 2025-12-02 (recent 5 months)\n",
            "üéØ Target achieved: 20,000 recent cs.AI papers!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Finalize papers dataset\n",
        "# ============================================================\n",
        "if MODE == 'infer':\n",
        "    # Already loaded papers from CSV in cell 8\n",
        "    df = pd.read_csv(f\"{PROJECT_PATH}/data/raw/arxiv_cs_ai_raw.csv\")\n",
        "    papers = df.to_dict('records')\n",
        "    dates = [p['date'] for p in papers]\n",
        "    print(f\"INFER mode: Loaded {len(papers):,} papers\")\n",
        "    print(f\"üìÖ Date range: {min(dates)} to {max(dates)}\")\n",
        "else:\n",
        "    # Use the combined unique papers\n",
        "    papers = unique_papers\n",
        "    print(f\"Final dataset: {len(papers)} papers\")\n",
        "    print(f\"üìÖ Date range: {min(dates)} to {max(dates)} (recent 5 months)\")\n",
        "    print(f\"üéØ Target achieved: 20,000 recent cs.AI papers!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a123fc52",
      "metadata": {
        "id": "a123fc52"
      },
      "source": [
        "## 4. Create DataFrame and Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "618d8755",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "618d8755",
        "outputId": "1dc8fe30-427e-4142-a1cb-32910cd03d97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame shape: (20000, 9)\n",
            "\n",
            "Columns: ['arxiv_id', 'title', 'abstract', 'authors', 'date', 'year_month', 'url', 'categories', 'primary_category']\n",
            "\n",
            "Date range: 2025-07-03 to 2025-12-02\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       arxiv_id                                              title  \\\n",
              "0  2512.03042v1  PPTArena: A Benchmark for Agentic PowerPoint E...   \n",
              "1  2512.03040v1  Video4Spatial: Towards Visuospatial Intelligen...   \n",
              "2  2512.03036v1  ViSAudio: End-to-End Video-Driven Binaural Spa...   \n",
              "3  2512.03028v1  SMP: Reusable Score-Matching Motion Priors for...   \n",
              "4  2512.03026v1  The Moral Consistency Pipeline: Continuous Eth...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  We introduce PPTArena, a benchmark for PowerPo...   \n",
              "1  We investigate whether video generative models...   \n",
              "2  Despite progress in video-to-audio generation,...   \n",
              "3  Data-driven motion priors that can guide agent...   \n",
              "4  The rapid advancement and adaptability of Larg...   \n",
              "\n",
              "                                             authors        date year_month  \\\n",
              "0  Michael Ofengenden, Yunze Man, Ziqi Pang, Yu-X...  2025-12-02    2025-12   \n",
              "1  Zeqi Xiao, Yiwei Zhao, Lingxiao Li, Yushi Lan,...  2025-12-02    2025-12   \n",
              "2  Mengchen Zhang, Qi Chen, Tong Wu, Zihan Liu, D...  2025-12-02    2025-12   \n",
              "3  Yuxuan Mu, Ziyu Zhang, Yi Shi, Minami Matsumot...  2025-12-02    2025-12   \n",
              "4  Saeid Jamshidi, Kawser Wazed Nafi, Arghavan Mo...  2025-12-02    2025-12   \n",
              "\n",
              "                                 url                  categories  \\\n",
              "0  http://arxiv.org/abs/2512.03042v1                cs.CV, cs.AI   \n",
              "1  http://arxiv.org/abs/2512.03040v1                cs.CV, cs.AI   \n",
              "2  http://arxiv.org/abs/2512.03036v1                cs.CV, cs.AI   \n",
              "3  http://arxiv.org/abs/2512.03028v1  cs.GR, cs.AI, cs.CV, cs.RO   \n",
              "4  http://arxiv.org/abs/2512.03026v1                cs.CL, cs.AI   \n",
              "\n",
              "  primary_category  \n",
              "0            cs.CV  \n",
              "1            cs.CV  \n",
              "2            cs.CV  \n",
              "3            cs.GR  \n",
              "4            cs.CL  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b3c4715-0831-47d1-94de-da4299490353\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>arxiv_id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>authors</th>\n",
              "      <th>date</th>\n",
              "      <th>year_month</th>\n",
              "      <th>url</th>\n",
              "      <th>categories</th>\n",
              "      <th>primary_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2512.03042v1</td>\n",
              "      <td>PPTArena: A Benchmark for Agentic PowerPoint E...</td>\n",
              "      <td>We introduce PPTArena, a benchmark for PowerPo...</td>\n",
              "      <td>Michael Ofengenden, Yunze Man, Ziqi Pang, Yu-X...</td>\n",
              "      <td>2025-12-02</td>\n",
              "      <td>2025-12</td>\n",
              "      <td>http://arxiv.org/abs/2512.03042v1</td>\n",
              "      <td>cs.CV, cs.AI</td>\n",
              "      <td>cs.CV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2512.03040v1</td>\n",
              "      <td>Video4Spatial: Towards Visuospatial Intelligen...</td>\n",
              "      <td>We investigate whether video generative models...</td>\n",
              "      <td>Zeqi Xiao, Yiwei Zhao, Lingxiao Li, Yushi Lan,...</td>\n",
              "      <td>2025-12-02</td>\n",
              "      <td>2025-12</td>\n",
              "      <td>http://arxiv.org/abs/2512.03040v1</td>\n",
              "      <td>cs.CV, cs.AI</td>\n",
              "      <td>cs.CV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2512.03036v1</td>\n",
              "      <td>ViSAudio: End-to-End Video-Driven Binaural Spa...</td>\n",
              "      <td>Despite progress in video-to-audio generation,...</td>\n",
              "      <td>Mengchen Zhang, Qi Chen, Tong Wu, Zihan Liu, D...</td>\n",
              "      <td>2025-12-02</td>\n",
              "      <td>2025-12</td>\n",
              "      <td>http://arxiv.org/abs/2512.03036v1</td>\n",
              "      <td>cs.CV, cs.AI</td>\n",
              "      <td>cs.CV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2512.03028v1</td>\n",
              "      <td>SMP: Reusable Score-Matching Motion Priors for...</td>\n",
              "      <td>Data-driven motion priors that can guide agent...</td>\n",
              "      <td>Yuxuan Mu, Ziyu Zhang, Yi Shi, Minami Matsumot...</td>\n",
              "      <td>2025-12-02</td>\n",
              "      <td>2025-12</td>\n",
              "      <td>http://arxiv.org/abs/2512.03028v1</td>\n",
              "      <td>cs.GR, cs.AI, cs.CV, cs.RO</td>\n",
              "      <td>cs.GR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2512.03026v1</td>\n",
              "      <td>The Moral Consistency Pipeline: Continuous Eth...</td>\n",
              "      <td>The rapid advancement and adaptability of Larg...</td>\n",
              "      <td>Saeid Jamshidi, Kawser Wazed Nafi, Arghavan Mo...</td>\n",
              "      <td>2025-12-02</td>\n",
              "      <td>2025-12</td>\n",
              "      <td>http://arxiv.org/abs/2512.03026v1</td>\n",
              "      <td>cs.CL, cs.AI</td>\n",
              "      <td>cs.CL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b3c4715-0831-47d1-94de-da4299490353')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b3c4715-0831-47d1-94de-da4299490353 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b3c4715-0831-47d1-94de-da4299490353');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-18ad9ceb-67a7-4d99-b063-d19200960194\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18ad9ceb-67a7-4d99-b063-d19200960194')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-18ad9ceb-67a7-4d99-b063-d19200960194 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20000,\n  \"fields\": [\n    {\n      \"column\": \"arxiv_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20000,\n        \"samples\": [\n          \"2509.20386v1\",\n          \"2511.12497v1\",\n          \"2510.01141v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19999,\n        \"samples\": [\n          \"Dynamic ReAct: Scalable Tool Selection for Large-Scale MCP Environments\",\n          \"SGuard-v1: Safety Guardrail for Large Language Models\",\n          \"Apriel-1.5-15b-Thinker\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19997,\n        \"samples\": [\n          \"This paper introduces MCTS-EP, an online learning framework that combines large language models (LLM) with Monte Carlo Tree Search (MCTS) for training embodied agents. MCTS-EP integrates three key components: MCTS-guided exploration for preference data collection, efficient multi-modal reasoning mechanism, and iterative training pipeline based on preference optimization. We theoretically prove that MCTS-EP achieves better performance bounds than conventional on-policy algorithms when the loss function is strongly convex, and demonstrate that it can be formulated as a search-enhanced variant of GAIL. MCTS-EP achieves state-of-the-art performace across serval benchmarks. In ALFWorld, it achieves 92% and 87% success rates for textual and visual tasks. In WebShop, it reaches an average reward of 0.81. MTCS-EP also reduces average interaction steps from from 18.7/19.5 to 10.2/9.9 steps in visual ALFWorld.Code available at: https://github.com/xuhang-2/Embodied-Agent-Planning\",\n          \"Patent text embeddings enable prior art search, technology landscaping, and patent analysis, yet existing benchmarks inadequately capture patent-specific challenges. We introduce PatenTEB, a comprehensive benchmark comprising 15 tasks across retrieval, classification, paraphrase, and clustering, with 2.06 million examples. PatenTEB employs domain-stratified splits, domain specific hard negative mining, and systematic coverage of asymmetric fragment-to-document matching scenarios absent from general embedding benchmarks. We develop the patembed model family through multi-task training, spanning 67M to 344M parameters with context lengths up to 4096 tokens. External validation shows strong generalization: patembed-base achieves state-of-the-art on MTEB BigPatentClustering.v2 (0.494 V-measure vs. 0.445 previous best), while patembed-large achieves 0.377 NDCG@100 on DAPFAM. Systematic ablations reveal that multi-task training improves external generalization despite minor benchmark costs, and that domain-pretrained initialization provides consistent advantages across task families. All resources will be made available at https://github.com/iliass-y/patenteb. Keywords: patent retrieval, sentence embeddings, multi-task learning, asymmetric retrieval, benchmark evaluation, contrastive learning.\",\n          \"Vision-language models (VLMs) have demonstrated impressive generalization across multimodal tasks, yet most evaluation benchmarks remain Western-centric, leaving open questions about their performance in culturally diverse and multilingual settings. To address this gap, we introduce IndicVisionBench, the first large-scale benchmark centered on the Indian subcontinent. Covering English and 10 Indian languages, our benchmark spans 3 multimodal tasks, including Optical Character Recognition (OCR), Multimodal Machine Translation (MMT), and Visual Question Answering (VQA), covering 6 kinds of question types. Our final benchmark consists of a total of ~5K images and 37K+ QA pairs across 13 culturally grounded topics. In addition, we release a paired parallel corpus of annotations across 10 Indic languages, creating a unique resource for analyzing cultural and linguistic biases in VLMs. We evaluate a broad spectrum of 8 models, from proprietary closed-source systems to open-weights medium and large-scale models. Our experiments reveal substantial performance gaps, underscoring the limitations of current VLMs in culturally diverse contexts. By centering cultural diversity and multilinguality, IndicVisionBench establishes a reproducible evaluation framework that paves the way for more inclusive multimodal research.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19531,\n        \"samples\": [\n          \"Liang Gong, Tommy, Wang, Sara Chaker, Yanchen Dong\",\n          \"Yu Yan, Sheng Sun, Zhe Wang, Yijun Lin, Zenghao Duan\",\n          \"Fasheng Xu, Xiaoyu Wang, Wei Chen, Karen Xie\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 153,\n        \"samples\": [\n          \"2025-09-09\",\n          \"2025-09-07\",\n          \"2025-08-27\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year_month\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"2025-12\",\n          \"2025-11\",\n          \"2025-07\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20000,\n        \"samples\": [\n          \"http://arxiv.org/abs/2509.20386v1\",\n          \"http://arxiv.org/abs/2511.12497v1\",\n          \"http://arxiv.org/abs/2510.01141v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2177,\n        \"samples\": [\n          \"cs.CV, cs.AI, cs.FL, cs.LG\",\n          \"cs.SE, cs.AI, cs.CL, cs.CR, cs.IR\",\n          \"cs.LG, cs.AI, q-bio.GN, q-bio.QM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"primary_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"math.HO\",\n          \"cs.LG\",\n          \"eess.SP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Create DataFrame\n",
        "df = pd.DataFrame(papers)\n",
        "\n",
        "print(f\"DataFrame shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d8957fb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8957fb8",
        "outputId": "7e93670f-5a43-4183-bc8f-4d7f67645ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Statistics:\n",
            "  Total papers: 20000\n",
            "  Unique dates: 153\n",
            "  Date range: 2025-07-03 to 2025-12-02\n",
            "\n",
            "Title length: mean=83, median=83\n",
            "Abstract length: mean=1340, median=1341\n"
          ]
        }
      ],
      "source": [
        "# Basic statistics\n",
        "print(\"Dataset Statistics:\")\n",
        "print(f\"  Total papers: {len(df)}\")\n",
        "print(f\"  Unique dates: {df['date'].nunique()}\")\n",
        "print(f\"  Date range: {df['date'].min()} to {df['date'].max()}\")\n",
        "\n",
        "# Text length statistics\n",
        "df['title_len'] = df['title'].str.len()\n",
        "df['abstract_len'] = df['abstract'].str.len()\n",
        "\n",
        "print(f\"\\nTitle length: mean={df['title_len'].mean():.0f}, median={df['title_len'].median():.0f}\")\n",
        "print(f\"Abstract length: mean={df['abstract_len'].mean():.0f}, median={df['abstract_len'].median():.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "33536339",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33536339",
        "outputId": "0231a0b6-96d1-4db4-b8cd-3a4d274b95f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Papers per month:\n",
            "year_month\n",
            "2025-07    3156\n",
            "2025-08    3819\n",
            "2025-09    4204\n",
            "2025-10    4821\n",
            "2025-11    3755\n",
            "2025-12     245\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Papers per month\n",
        "papers_per_month = df['year_month'].value_counts().sort_index()\n",
        "print(\"Papers per month:\")\n",
        "print(papers_per_month)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b160792c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b160792c",
        "outputId": "cb7bd943-6836-46aa-f8da-786b1858ed8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample abstracts:\n",
            "================================================================================\n",
            "\n",
            "Title: PPTArena: A Benchmark for Agentic PowerPoint Editing\n",
            "Date: 2025-12-02\n",
            "Abstract: We introduce PPTArena, a benchmark for PowerPoint editing that measures reliable modifications to real slides under natural-language instructions. In contrast to image-PDF renderings or text-to-slide generation, PPTArena focuses on in-place editing across 100 decks, 2125 slides, and over 800 targete...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation\n",
            "Date: 2025-12-02\n",
            "Abstract: We investigate whether video generative models can exhibit visuospatial intelligence, a capability central to human cognition, using only visual data. To this end, we present Video4Spatial, a framework showing that video diffusion models conditioned solely on video-based scene context can perform co...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: ViSAudio: End-to-End Video-Driven Binaural Spatial Audio Generation\n",
            "Date: 2025-12-02\n",
            "Abstract: Despite progress in video-to-audio generation, the field focuses predominantly on mono output, lacking spatial immersion. Existing binaural approaches remain constrained by a two-stage pipeline that first generates mono audio and then performs spatialization, often resulting in error accumulation an...\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Sample abstracts\n",
        "print(\"Sample abstracts:\")\n",
        "print(\"=\" * 80)\n",
        "for i, row in df.head(3).iterrows():\n",
        "    print(f\"\\nTitle: {row['title']}\")\n",
        "    print(f\"Date: {row['date']}\")\n",
        "    print(f\"Abstract: {row['abstract'][:300]}...\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34a0bddb",
      "metadata": {
        "id": "34a0bddb"
      },
      "source": [
        "## 5. Save Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b782b907",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b782b907",
        "outputId": "e97ae89a-405e-4f36-dadb-0cdd93bf4199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw JSON saved to: /content/drive/MyDrive/BERTopic-arXiv-Analysis/data/raw/arxiv_cs_ai_raw.json\n",
            "Raw CSV saved to: /content/drive/MyDrive/BERTopic-arXiv-Analysis/data/raw/arxiv_cs_ai_raw.csv\n",
            "\n",
            "Total records saved: 20000\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Save raw data (TRAIN mode only)\n",
        "# ============================================================\n",
        "if MODE == 'infer':\n",
        "    print(\"INFER mode: Skipping save (data already exists)\")\n",
        "    print(f\"Existing data at: {PROJECT_PATH}/data/raw/arxiv_cs_ai_raw.csv\")\n",
        "else:\n",
        "    # Save raw data as JSON\n",
        "    raw_json_path = f\"{PROJECT_PATH}/data/raw/arxiv_cs_ai_raw.json\"\n",
        "    with open(raw_json_path, 'w') as f:\n",
        "        json.dump(papers, f, indent=2)\n",
        "    print(f\"Raw JSON saved to: {raw_json_path}\")\n",
        "\n",
        "    # Save as CSV (more convenient for pandas)\n",
        "    raw_csv_path = f\"{PROJECT_PATH}/data/raw/arxiv_cs_ai_raw.csv\"\n",
        "    df.to_csv(raw_csv_path, index=False)\n",
        "    print(f\"Raw CSV saved to: {raw_csv_path}\")\n",
        "\n",
        "    print(f\"\\nTotal records saved: {len(df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74ac1019",
      "metadata": {
        "id": "74ac1019"
      },
      "source": [
        "## 6. Data Quality Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e3fd9151",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3fd9151",
        "outputId": "cfbd863b-b54f-4e59-80e1-18364e182b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            "arxiv_id            0\n",
            "title               0\n",
            "abstract            0\n",
            "authors             0\n",
            "date                0\n",
            "year_month          0\n",
            "url                 0\n",
            "categories          0\n",
            "primary_category    0\n",
            "title_len           0\n",
            "abstract_len        0\n",
            "dtype: int64\n",
            "\n",
            "Duplicate arxiv_ids: 0\n",
            "Short abstracts (<50 chars): 0\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check for duplicates\n",
        "n_duplicates = df['arxiv_id'].duplicated().sum()\n",
        "print(f\"\\nDuplicate arxiv_ids: {n_duplicates}\")\n",
        "\n",
        "# Check for empty abstracts\n",
        "empty_abstracts = (df['abstract'].str.len() < 50).sum()\n",
        "print(f\"Short abstracts (<50 chars): {empty_abstracts}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.13.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}